{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8171833-67ad-4b81-bbef-195b18524b6d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Homework 1. Part 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7958fe00-5a97-430e-b0fa-6816c4834ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fabd7e9f-bd81-4fa3-a1c6-24bb3ebd6dcd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda is available'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setting default device\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "display(f'{device} is available')\n",
    "\n",
    "dtype = torch.float\n",
    "torch.set_default_device(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4e0328-0c09-4d24-a146-1deb2d788829",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Modifiable model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e8d0be4-3023-4b72-ba29-5ba7eb9bb34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChangeableNetwork(nn.Module):\n",
    "    def __init__(self, modification=512):\n",
    "        super().__init__()\n",
    "        self.linear_relu = nn.Sequential(\n",
    "            nn.Linear(28*28, modification),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(modification,modification),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(modification, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        flat = nn.Flatten()\n",
    "        x = flat(x)\n",
    "        logits = self.linear_relu(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb5302c-160f-4c43-b099-edbc128f683c",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "071cb222-1a1e-4282-8274-0b0751397c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnt_model_params(model):\n",
    "    \"\"\"Count model parameters\"\"\"\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters():\n",
    "            count+=param.numel()\n",
    "    return count\n",
    "\n",
    "def display_model_info(model_name, model):\n",
    "    \"\"\" Display model information\"\"\"\n",
    "    count = 0\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, nn.Module):\n",
    "            count+=1\n",
    "    display(model)\n",
    "    display(f\"{model_name}. parameters: {cnt_model_params(model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e34cccf-454c-42d5-ba5e-d5910b00d1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly changed the lavels on the training dataset. Kept labels the same on test dataset.\n",
    "training_ds = datasets.MNIST(root=\"data\", train=True, download=True, transform=ToTensor())\n",
    "test_ds = datasets.MNIST(root='data', train=False, download=True, transform=ToTensor())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0266835a-8218-4437-bd72-3525e970fc26",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training & eval loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc93fa03-3f1b-4fec-bb18-dd56e212842c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nmist_train_loop(dataloader, model, loss_fn, optimize):\n",
    "    model.train()\n",
    "    num_batches = len(dataloader)\n",
    "    train_loss, correct = 0,0\n",
    "    size = len(dataloader.dataset)\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X = X.to(device)\n",
    "        optimize.zero_grad()\n",
    "        y_pred = model(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss.item()\n",
    "        correct += (y_pred.argmax(dim=1) == y).type(torch.float).sum().item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimize.step()\n",
    "    \n",
    "    train_loss /= num_batches\n",
    "    correct /=size\n",
    "    return train_loss, correct\n",
    "        \n",
    "def nmist_val_loop(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    size= len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0,0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X,y in dataloader:\n",
    "            X = X.to(device)\n",
    "            y_pred = model(X)\n",
    "            test_loss += loss_fn(y_pred, y).item()\n",
    "            correct += (y_pred.argmax(dim=1) == y).type(torch.float).sum().item()\n",
    "    \n",
    "    test_loss /= num_batches\n",
    "    correct /=size\n",
    "    return test_loss, correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9cb8ef-eda9-4193-9758-417f7fab8aa4",
   "metadata": {},
   "source": [
    "## Flatness v.s. Generalization part2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbea0c2e-ffad-4cd5-ab3f-52a05953c114",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChangeableNetwork(\n",
       "  (linear_relu): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'1. parameters: 669706'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ChangeableNetwork(\n",
       "  (linear_relu): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2. parameters: 669706'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create models and with different Hidden values\n",
    "m1, m2 = ChangeableNetwork(512), ChangeableNetwork(512)\n",
    "display_model_info(1, m1)\n",
    "display_model_info(2, m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3345fd57-4bc1-4b69-b9db-280382b3f8c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Training & eval: Model with random labels'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 0. Training_loss: 2.2774649550919848. Val_loss: 2.252709628670079. Training_accuracy: 0.3039. Val_accuracy: 0.4813'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 1. Training_loss: 2.2230263071527867. Val_loss: 2.1843814910597104. Training_accuracy: 0.5777833333333333. Val_accuracy: 0.6401'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 2. Training_loss: 2.135086968509373. Val_loss: 2.0675799254399196. Training_accuracy: 0.6563666666666667. Val_accuracy: 0.68'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 3. Training_loss: 1.9832452155633775. Val_loss: 1.8686661173583596. Training_accuracy: 0.6887666666666666. Val_accuracy: 0.7123'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 4. Training_loss: 1.74193851487723. Val_loss: 1.5774701097208983. Training_accuracy: 0.7195333333333334. Val_accuracy: 0.7412'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hyperparameters\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "epochs = 15\n",
    "lr = 1e-3\n",
    "\n",
    "models = (m1,m2)\n",
    "\n",
    "batch_sizes = (64, 2048)\n",
    "\n",
    "fit_df = pd.DataFrame()\n",
    "\n",
    "for batch_size, model in zip(batch_sizes, models):\n",
    "    optimizer1 = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    display(\"Training & eval: Model with random labels\")\n",
    "\n",
    "    # Dataloader\n",
    "    training_dl = DataLoader(training_ds, batch_size=batch_size)\n",
    "    test_dl = DataLoader(test_ds, batch_size=batch_size)\n",
    "   \n",
    "    for epoch in range(epochs):\n",
    "        train_loss, t_correct = nmist_train_loop(training_dl, model, loss_fn, optimizer1)\n",
    "        val_loss, v_correct = nmist_val_loop(test_dl, model, loss_fn)\n",
    "        display(f'Epoch {epoch}. Training_loss: {train_loss}. Val_loss: {val_loss}. Training_accuracy: {t_correct}. Val_accuracy: {v_correct}')\n",
    "    display(\"Done\")\n",
    "    \n",
    "    #if fit_df.empty:\n",
    "    #    fit_df = pd.DataFrame([[epoch, train_loss, val_loss, t_correct, v_correct, cnt_model_params(model)]], columns=['epoch','train_loss','val_loss', 'train_acc', 'v_acc','parameters'])\n",
    "    #else:\n",
    "    #    columns=['epoch','train_loss','val_loss', 'train_acc', 'v_acc','parameters']\n",
    "    #    fit_df = pd.concat([fit_df, pd.DataFrame([[epoch, train_loss, val_loss, t_correct, v_correct, cnt_model_params(model)]], columns=columns )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ccfceb-6cd6-4f35-90f0-6136c363e8b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Saving weights for later\n",
    "torch.save(m1.state_dict(), 'm1.pth')\n",
    "torch.save(m2.state_dict(), 'm2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a6cb88-f4d2-44bc-8c38-2ce8a723110c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m1_params = torch.nn.utils.parameters_to_vector(m1.parameters())\n",
    "m2_params = torch.nn.utils.parameters_to_vector(m2.parameters())\n",
    "alphas = torch.linspace(-2,2, 20)\n",
    "\n",
    "theta_params_list = [(alpha, (1-alpha) * m1_params + alpha * m2_params) for alpha in alphas]\n",
    "theta_params_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b50cd6-8bd7-4e5b-af53-5d0a8406fc94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#theta_model = ChangeableNetwork(512)\n",
    "#torch.nn.utils.vector_to_parameters(theta_params, theta_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b72cb1-6cb9-4c46-b397-de1c7e0c1f7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training on theta_models\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "epochs = 5\n",
    "lr = 1e-3\n",
    "batch_size=64\n",
    "\n",
    "theta_df = pd.DataFrame()\n",
    "\n",
    "for cur_alpha, theta_params in theta_params_list:\n",
    "    \n",
    "    model = ChangeableNetwork(512)\n",
    "    torch.nn.utils.vector_to_parameters(theta_params, theta_model.parameters())\n",
    "    \n",
    "    optimizer1 = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    display(f\"Training & eval: Model with alpha: {cur_alpha}\")\n",
    "\n",
    "    # Dataloader\n",
    "    training_dl = DataLoader(training_ds, batch_size=batch_size)\n",
    "    test_dl = DataLoader(test_ds, batch_size=batch_size)\n",
    "   \n",
    "    for epoch in range(epochs):\n",
    "        train_loss, t_correct = nmist_train_loop(training_dl, model, loss_fn, optimizer1)\n",
    "        val_loss, v_correct = nmist_val_loop(test_dl, model, loss_fn)\n",
    "        display(f'Epoch {epoch}. Training_loss: {train_loss}. Val_loss: {val_loss}. Training_accuracy: {t_correct}. Val_accuracy: {v_correct}')\n",
    "    display(\"Done\")\n",
    "    if theta_df.empty:\n",
    "        theta_df = pd.DataFrame([[cur_alpha.item(), train_loss, val_loss, t_correct, v_correct]], columns=['alpha', 'train_loss', 'val_loss','t_acc','v_acc'])\n",
    "    else:\n",
    "        theta_df = pd.concat([theta_df, pd.DataFrame([[cur_alpha.item(), train_loss, val_loss, t_correct, v_correct]], columns=['alpha', 'train_loss', 'val_loss','t_acc','v_acc'])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcd272b-bd5a-4f14-a321-a099757e91ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "theta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15a8498-f558-4c12-9f9b-e56f9e13aabc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 'train_loss','val_loss', 'train_acc', 'v_acc','parameters\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(theta_df.alpha, theta_df.train_loss, color = 'tab:red', marker='v')\n",
    "ax.plot(theta_df.alpha, theta_df.val_loss, color= 'tab:red', marker='x', linestyle='dashed')\n",
    "ax.set_xlabel('alpha')\n",
    "ax.set_ylabel('loss', color='tab:red')\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(theta_df.alpha, theta_df.t_acc, color='tab:blue', marker = 'v')\n",
    "ax2.plot(theta_df.alpha, theta_df.v_acc, color='tab:blue', marker = 'x', linestyle='dashed')\n",
    "ax2.set_ylabel('accuracy', color='tab:blue')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b988a56e-5b97-4f47-9065-8726b5aedf73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ax.scatter(theta_df.alpha, fit_df.train_loss, label='train_loss')\n",
    "ax.scatter(fit_df.parameters, fit_df.val_loss, label='val_loss')\n",
    "ax.legend()\n",
    "ax.set_xlabel('number of parameters')\n",
    "ax.set_ylabel('loss')\n",
    "ax.grid(True)\n",
    "plt.title('loss')\n",
    "\n",
    "fig2, ax2 = plt.subplots()\n",
    "ax2.scatter(fit_df.parameters, fit_df.train_acc, label='training_acc')\n",
    "ax2.scatter(fit_df.parameters, fit_df.v_acc, label='testing_acc')\n",
    "ax2.legend()\n",
    "ax2.set_xlabel('number of parameters')\n",
    "ax2.set_ylabel('accuracy')\n",
    "ax2.grid(True)\n",
    "plt.title('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8791286-5295-42cf-ad12-b8fee6b11d63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
