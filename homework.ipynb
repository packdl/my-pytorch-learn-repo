{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DNN - Dense layers\n",
    "CNN - Convolutional neural network\n",
    "\n",
    "# 1-1 - \n",
    "## rank of input x from 0 to 2pi. \n",
    "Do not need to set the # of parameters equal, just close.\n",
    "\n",
    "First figure is training loss\n",
    "2nd figure is prediction of each model\n",
    "\n",
    "Import MNIST or CIFAR-10 from Torch vision. Use either CNN or DNN. Show loss and accuracy. Comment on results & show observservations\n",
    "\n",
    "# 1-2\n",
    "- Collect parameters of the models - Grab from every layer - Collect and put into 1 dimensional feaure than reduce to a feature with only 2 numbers\n",
    "- Look up PCA\n",
    "- FIgiure out how to compute second order optimization method ex: Newton's method or Levenberg-Marquardt algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-1 Training on a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports of Pytorch and matplotlib and other supporting modules\n",
    " \n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting default device\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "f'{device} is available'\n",
    "\n",
    "dtype = torch.float\n",
    "torch.set_default_device(device)\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimize, epoch):\n",
    "    \"\"\"Training loop funciton for non-linear function\"\"\"\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        y_pred = model(X)\n",
    "        y_pred = y_pred.unsqueeze(1)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimize.step()\n",
    "        optimize.zero_grad()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if epoch % 100 == 0:\n",
    "            print(epoch, loss.item())\n",
    "\n",
    "def val_loop(dataloader, model, loss_fn, epoch):\n",
    "    \"\"\"Eval loop function for non-linear function\"\"\"\n",
    "    model.eval()\n",
    "    size= len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0,0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X,y in dataloader:\n",
    "            y_pred = model(X)\n",
    "            y_pred = y_pred.unsqueeze(1)\n",
    "            test_loss += loss_fn(y_pred, y).item()\n",
    "            correct +=(y_pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    \n",
    "    test_loss /= num_batches\n",
    "    correct /=size\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        display(f\"Accuracy: {(100*correct)}%, Avg loss: {test_loss}\")\n",
    "\n",
    "    return test_loss\n",
    "\n",
    "def cnt_model_params(model):\n",
    "    \"\"\"Count model parameters\"\"\"\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters():\n",
    "            count+=param.numel()\n",
    "    return count\n",
    "\n",
    "def display_model_info(model_name, model):\n",
    "    \"\"\" Display model information\"\"\"\n",
    "    count = 0\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, nn.Module):\n",
    "            count+=1\n",
    "    display(model)\n",
    "    display(f\"{model_name}. parameters: {cnt_model_params(model)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosNetwork(nn.Module):\n",
    "        \"\"\"First DNN for Cosine function\"\"\"\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.flatten = nn.Flatten()\n",
    "            self.linear_relu_stack = nn.Sequential(\n",
    "                nn.Linear(1, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128, 12),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(12, 1),\n",
    "                torch.nn.Flatten(0,1)\n",
    "            )\n",
    "        \n",
    "        def forward(self, x):\n",
    "              logits = self.linear_relu_stack(x)\n",
    "              return logits\n",
    "        \n",
    "class CosNetwork2(nn.Module):\n",
    "        \"\"\"second DNN for Cosine function\"\"\"\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.flatten = nn.Flatten()\n",
    "            self.linear_relu_stack = nn.Sequential(\n",
    "                nn.Linear(1, 453),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(453, 2),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(2,1),\n",
    "                torch.nn.Flatten(0,1)\n",
    "            )\n",
    "        \n",
    "        def forward(self, x):\n",
    "              #x=self.flatten(x)\n",
    "              logits = self.linear_relu_stack(x)\n",
    "              return logits\n",
    "\n",
    "class CosNetwork3(nn.Module):\n",
    "        \"\"\"Third DNN for Cosine function\"\"\"\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.flatten = nn.Flatten()\n",
    "            self.linear_relu_stack = nn.Sequential(\n",
    "                nn.Linear(1, 20),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(20, 20),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(20, 20),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(20, 14),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(14, 12),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(12, 10),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(10, 10),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(10,10),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(10, 9),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(9, 1),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(1,1),\n",
    "                torch.nn.Flatten(0,1)\n",
    "            )\n",
    "        \n",
    "        def forward(self, x):\n",
    "              logits = self.linear_relu_stack(x)\n",
    "              return logits\n",
    "        \n",
    "\n",
    "cos_model1, cos_model2, cos_model3 = CosNetwork(), CosNetwork2(), CosNetwork3()\n",
    "\n",
    "display_model_info(\"cos_model1\", cos_model1)\n",
    "display_model_info(\"cos_model2\", cos_model2)\n",
    "display_model_info(\"cos_model3\", cos_model3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training & Testing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(-math.pi, math.pi, 5000, dtype=dtype)\n",
    "y = torch.cos(x)\n",
    "\n",
    "lossy1, lossy2, lossy3 = list(), list(), list()\n",
    "epochx1, epochx2, epochx3 = list(), list(), list()\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "epochs = 20001\n",
    "lr = 1e-3\n",
    "batch_size=100\n",
    "optimizer1 = torch.optim.SGD(cos_model1.parameters(), lr=lr)\n",
    "train_dataloader = DataLoader(TensorDataset(x.unsqueeze(1),y.unsqueeze(1)), batch_size=batch_size)\n",
    "val_dataloader = DataLoader(TensorDataset(x.unsqueeze(1),y.unsqueeze(1)), batch_size=batch_size)\n",
    "patience = 5\n",
    "best_val_loss = float('inf')\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "display(\"Training & eval: cos1 model\")\n",
    "for epoch in range(epochs):\n",
    "    train_loop(train_dataloader, cos_model1, loss_fn, optimizer1, epoch)\n",
    "    val_loss = val_loop(val_dataloader, cos_model1, loss_fn, epoch)\n",
    "\n",
    "    if epoch%100 == 0:\n",
    "        epochx1.append(epoch)\n",
    "        lossy1.append(val_loss)\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_without_improvement = 0\n",
    "    else:\n",
    "        epochs_without_improvement +=1\n",
    "\n",
    "    if epochs_without_improvement >= patience:\n",
    "        display(f'Convergence reached at {epoch}')\n",
    "        break\n",
    "display(\"Done\")\n",
    "\n",
    "optimizer2 = torch.optim.SGD(cos_model2.parameters(), lr=lr)\n",
    "best_val_loss = float('inf')\n",
    "epochs_without_improvement = 0\n",
    "display(\"Training & eval: cos2 model\")\n",
    "for epoch in range(epochs):\n",
    "    train_loop(train_dataloader, cos_model2, loss_fn, optimizer2, epoch)\n",
    "    val_loss = val_loop(val_dataloader, cos_model2, loss_fn, epoch)\n",
    "\n",
    "    if epoch%100 == 0:\n",
    "        epochx2.append(epoch)\n",
    "        lossy2.append(val_loss)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_without_improvement = 0\n",
    "    else:\n",
    "        epochs_without_improvement +=1\n",
    "\n",
    "    if epochs_without_improvement >= patience:\n",
    "        display(f'Convergence reached at {epoch}')\n",
    "        break\n",
    "display(\"Done\")\n",
    "\n",
    "optimizer3 = torch.optim.SGD(cos_model3.parameters(), lr=lr)\n",
    "best_val_loss = float('inf')\n",
    "epochs_without_improvement = 0\n",
    "display(\"Training & eval: cos3 model\")\n",
    "for epoch in range(epochs):\n",
    "    train_loop(train_dataloader, cos_model3, loss_fn, optimizer3, epoch)\n",
    "    val_loss = val_loop(val_dataloader, cos_model3, loss_fn, epoch)\n",
    "\n",
    "    if epoch%100 == 0:\n",
    "        epochx3.append(epoch)\n",
    "        lossy3.append(val_loss)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_without_improvement = 0\n",
    "    else:\n",
    "        epochs_without_improvement +=1\n",
    "\n",
    "    if epochs_without_improvement >= patience:\n",
    "        display(f'Convergence reached at {epoch}')\n",
    "        break\n",
    "display(\"Done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(cos_model1.state_dict(), 'cosmodel1_weights.pth')\n",
    "torch.save(cos_model2.state_dict(), 'cosmodel2_weights.pth')\n",
    "torch.save(cos_model3.state_dict(), 'cosmodel3_weights.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting model loss and ground truth for cosine neural networks\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(epochx1, lossy1, epochx2, lossy2, epochx3, lossy3)\n",
    "ax.set(xlabel=\"epochs\",ylabel=\"loss\", title=\"Model loss\")\n",
    "ax.legend(labels=['cos_model1','cos_model2','cos_model3'])\n",
    "\n",
    "fig2, ax2 = plt.subplots()\n",
    "x = torch.linspace(-math.pi, math.pi, 5000, dtype=dtype)\n",
    "y = torch.cos(x)\n",
    "\n",
    "with torch.no_grad():\n",
    "    m1_y = cos_model1(x.unsqueeze(1)).cpu().numpy()\n",
    "    m2_y = cos_model2(x.unsqueeze(1)).cpu().numpy()\n",
    "    m3_y = cos_model3(x.unsqueeze(1)).cpu().numpy()\n",
    "    x = x.cpu().numpy()\n",
    "    y = y.cpu().numpy()\n",
    "\n",
    "ax2.plot(x, m1_y, x, m2_y, x, m3_y, x, y)\n",
    "ax2.set(xlabel='x',ylabel='y', title='Ground truth')\n",
    "ax2.legend(labels=['cos_model1', 'cos_model2','cos_model3', 'Ground Truth'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-1. Training on actual task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "training_ds = datasets.MNIST(root=\"data\", train=True, download=True, transform=ToTensor())\n",
    "test_ds = datasets.MNIST(root='data', train=False, download=True, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMISTNetwork1(nn.Module):\n",
    "        \"\"\"First CNN for NMIST\"\"\"\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.seq = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 5), \n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(1), \n",
    "            nn.Linear(18432, 128),\n",
    "            nn.Linear(128, 10),\n",
    "            )\n",
    "        \n",
    "        def forward(self, x):\n",
    "              output = self.seq(x)\n",
    "              return output\n",
    "        \n",
    "class NMISTNetwork2(nn.Module):\n",
    "        \"\"\"Second CNN for NMIST\"\"\"\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.seq = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 5), \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(1), \n",
    "            nn.Linear(25600, 128),\n",
    "            nn.Linear(128, 10),\n",
    "            )\n",
    "        \n",
    "        def forward(self, x):\n",
    "              output = self.seq(x)\n",
    "              return output\n",
    "        \n",
    "class NMISTNetwork3(nn.Module):\n",
    "        \"\"\"Third CNN for NMIST\"\"\"\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.seq = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 5), \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 5),\n",
    "            nn.Dropout(.25),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 5),\n",
    "            nn.Flatten(1), \n",
    "            nn.Linear(16384, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10),\n",
    "            )\n",
    "        \n",
    "        def forward(self, x):\n",
    "              output = self.seq(x)\n",
    "              return output\n",
    "        \n",
    "\n",
    "nmist1, nmist2, nmist3 = NMISTNetwork1(), NMISTNetwork2(), NMISTNetwork3()\n",
    "display_model_info('nmist1', nmist1)\n",
    "display_model_info('nmist2', nmist2)\n",
    "display_model_info('nmist3', nmist3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nmist_train_loop(dataloader, model, loss_fn, optimize, epoch):\n",
    "    \"\"\"Training loop funciton for non-linear function\"\"\"\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X = X.to(device)\n",
    "        optimize.zero_grad()\n",
    "        y_pred = model(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimize.step()\n",
    "        \n",
    "def nmist_val_loop(dataloader, model, loss_fn, epoch):\n",
    "    \"\"\"Eval loop function for non-linear function\"\"\"\n",
    "    model.eval()\n",
    "    size= len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0,0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X,y in dataloader:\n",
    "            X = X.to(device)\n",
    "            y_pred = model(X)\n",
    "            test_loss += loss_fn(y_pred, y).item()\n",
    "            correct += (y_pred.argmax(dim=1) == y).type(torch.float).sum().item()\n",
    "    \n",
    "    test_loss /= num_batches\n",
    "    correct /=size\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        display(f\"Epoch {epoch}. Accuracy: {(100*correct)}%, Avg loss: {test_loss}\")\n",
    "\n",
    "    return test_loss, correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossy1, lossy2, lossy3 = list(), list(), list()\n",
    "epochx1, epochx2, epochx3 = list(), list(), list()\n",
    "accy1, accy2, accy3 = list(), list(), list()\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "epochs = 75\n",
    "lr = 1.5e-2\n",
    "batch_size=150\n",
    "\n",
    "training_dl = DataLoader(training_ds, batch_size=batch_size)\n",
    "test_dl = DataLoader(test_ds, batch_size=batch_size)\n",
    "\n",
    "patience = 5\n",
    "best_val_loss = float('inf')\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "optimizer1 = torch.optim.SGD(nmist1.parameters(), lr=lr)\n",
    "display(\"Training & eval: nmist1 model\")\n",
    "for epoch in range(epochs):\n",
    "    nmist_train_loop(training_dl, nmist1, loss_fn, optimizer1, epoch)\n",
    "    val_loss, correct = nmist_val_loop(test_dl, nmist1, loss_fn, epoch)\n",
    "\n",
    "    if epoch%2 == 0:\n",
    "        epochx1.append(epoch)\n",
    "        lossy1.append(val_loss)\n",
    "        accy1.append(correct)\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_without_improvement = 0\n",
    "    else:\n",
    "        epochs_without_improvement +=1\n",
    "\n",
    "    if epochs_without_improvement >= patience:\n",
    "        display(f'Convergence reached at {epoch}')\n",
    "        if epoch%2 !=0:\n",
    "            epochx1.append(epoch)\n",
    "            lossy1.append(val_loss)\n",
    "            accy1.append(correct)\n",
    "        break\n",
    "display(\"Done\")\n",
    "\n",
    "optimizer2 = torch.optim.SGD(nmist2.parameters(), lr=lr)\n",
    "best_val_loss = float('inf')\n",
    "epochs_without_improvement = 0\n",
    "display(\"Training & eval: nmist2 model\")\n",
    "for epoch in range(epochs):\n",
    "    nmist_train_loop(training_dl, nmist2, loss_fn, optimizer2, epoch)\n",
    "    val_loss, correct = nmist_val_loop(test_dl, nmist2, loss_fn, epoch)\n",
    "\n",
    "    if epoch%2 == 0:\n",
    "        epochx2.append(epoch)\n",
    "        lossy2.append(val_loss)\n",
    "        accy2.append(correct)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_without_improvement = 0\n",
    "    else:\n",
    "        epochs_without_improvement +=1\n",
    "\n",
    "    if epochs_without_improvement >= patience:\n",
    "        display(f'Convergence reached at {epoch}')\n",
    "        if epoch%2 != 0:\n",
    "            epochx2.append(epoch)\n",
    "            lossy2.append(val_loss)\n",
    "            accy2.append(correct)\n",
    "        break\n",
    "display(\"Done\")\n",
    "\n",
    "optimizer3 = torch.optim.SGD(nmist3.parameters(), lr=lr)\n",
    "best_val_loss = float('inf')\n",
    "epochs_without_improvement = 0\n",
    "display(\"Training & eval: nmist3 model\")\n",
    "for epoch in range(epochs):\n",
    "    nmist_train_loop(training_dl, nmist3, loss_fn, optimizer3, epoch)\n",
    "    val_loss, correct = nmist_val_loop(test_dl, nmist3, loss_fn, epoch)\n",
    "\n",
    "    if epoch%2 == 0:\n",
    "        epochx3.append(epoch)\n",
    "        lossy3.append(val_loss)\n",
    "        accy3.append(correct)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_without_improvement = 0\n",
    "    else:\n",
    "        epochs_without_improvement +=1\n",
    "\n",
    "    if epochs_without_improvement >= patience:\n",
    "        display(f'Convergence reached at {epoch}')\n",
    "        if epoch%2 != 0:\n",
    "            epochx3.append(epoch)\n",
    "            lossy3.append(val_loss)\n",
    "            accy3.append(correct)\n",
    "        break\n",
    "display(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(nmist1.state_dict(), 'nmist1_weights.pth')\n",
    "torch.save(nmist2.state_dict(), 'nmist2_weights.pth')\n",
    "torch.save(nmist3.state_dict(), 'nmist3_weights.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(epochx1, lossy1, epochx2, lossy2, epochx3, lossy3)\n",
    "ax.set(xlabel=\"epochs\",ylabel=\"loss\", title=\"Model loss\")\n",
    "ax.legend(labels=['nmist1','nmist2','nmist3'])\n",
    "\n",
    "fig2, ax2 = plt.subplots()\n",
    "x = torch.linspace(-math.pi, math.pi, 5000, dtype=dtype)\n",
    "y = torch.cos(x)\n",
    "\n",
    "ax2.plot(epochx1, accy1, epochx2, accy2, epochx3, accy3)\n",
    "ax2.set(xlabel='epochs',ylabel='Accuracy', title='Model accuracy')\n",
    "ax2.legend(labels=['nmist1', 'nmist2','nmist3'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
