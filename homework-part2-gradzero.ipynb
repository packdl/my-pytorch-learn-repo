{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f21e5c97-ab53-435c-87b3-d71a2b99c206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports of Pytorch and matplotlib and other supporting modules\n",
    " \n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a7dd5da-5bc7-4f21-a495-f0e50a6f0c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda is available'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setting default device\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "display(f'{device} is available')\n",
    "\n",
    "dtype = torch.float\n",
    "torch.set_default_device(device)\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimize, epoch):\n",
    "    \"\"\"Training loop funciton for non-linear function\"\"\"\n",
    "    model.train()\n",
    "    training_loss = 0\n",
    "    num_batches = len(dataloader)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        y_pred = model(X)\n",
    "        y_pred = y_pred.unsqueeze(1)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        training_loss+=loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimize.step()\n",
    "        optimize.zero_grad()\n",
    "  \n",
    "    training_loss /= num_batches\n",
    "    return training_loss\n",
    "\n",
    "def val_loop(dataloader, model, loss_fn, epoch):\n",
    "    \"\"\"Eval loop function for non-linear function\"\"\"\n",
    "    model.eval()\n",
    "    size= len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0,0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X,y in dataloader:\n",
    "            y_pred = model(X)\n",
    "            y_pred = y_pred.unsqueeze(1)\n",
    "            test_loss += loss_fn(y_pred, y).item()\n",
    "            correct +=(y_pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    \n",
    "    test_loss /= num_batches\n",
    "    correct /=size\n",
    "\n",
    "    #if epoch % 100 == 0:\n",
    "    #    display(f\"Accuracy: {(100*correct)}%, Avg loss: {test_loss}\")\n",
    "\n",
    "    return test_loss\n",
    "\n",
    "def cnt_model_params(model):\n",
    "    \"\"\"Count model parameters\"\"\"\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters():\n",
    "            count+=param.numel()\n",
    "    return count\n",
    "\n",
    "def display_model_info(model_name, model):\n",
    "    \"\"\" Display model information\"\"\"\n",
    "    count = 0\n",
    "    for module in model.modules():\n",
    "        if isinstance(module, nn.Module):\n",
    "            count+=1\n",
    "    display(model)\n",
    "    display(f\"{model_name}. parameters: {cnt_model_params(model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b971265-c5ec-423a-8902-e7f7cbd5b301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CosNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=1, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=12, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=12, out_features=1, bias=True)\n",
       "    (5): Flatten(start_dim=0, end_dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'cos_model1. parameters: 1817'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class CosNetwork(nn.Module):\n",
    "        \"\"\"First DNN for Cosine function\"\"\"\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.flatten = nn.Flatten()\n",
    "            self.linear_relu_stack = nn.Sequential(\n",
    "                nn.Linear(1, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128, 12),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(12, 1),\n",
    "                torch.nn.Flatten(0,1)\n",
    "            )\n",
    "        \n",
    "        def forward(self, x):\n",
    "              logits = self.linear_relu_stack(x)\n",
    "              return logits\n",
    "        \n",
    "cos_model1 = CosNetwork()\n",
    "display_model_info(\"cos_model1\", cos_model1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d46ed5cb-6163-4563-832d-3a0196332cdb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Training on original loss function'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 0. Train loss: 0.685237318277359. Test loss: 0.687676191329956.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 10. Train loss: 0.615065336227417. Test loss: 0.6159908771514893.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 20. Train loss: 0.5618208646774292. Test loss: 0.5605651140213013.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 30. Train loss: 0.5183338075876236. Test loss: 0.5155771970748901.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 40. Train loss: 0.48615869879722595. Test loss: 0.48309189081192017.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 50. Train loss: 0.4632952809333801. Test loss: 0.4596228003501892.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 60. Train loss: 0.4422297179698944. Test loss: 0.4380805194377899.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 70. Train loss: 0.42119134962558746. Test loss: 0.4167417287826538.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 80. Train loss: 0.3992723673582077. Test loss: 0.39474108815193176.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 90. Train loss: 0.3799649327993393. Test loss: 0.37634003162384033.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 100. Train loss: 0.36694158613681793. Test loss: 0.3633324205875397.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 110. Train loss: 0.35409417748451233. Test loss: 0.3503592312335968.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 120. Train loss: 0.3405783772468567. Test loss: 0.33666980266571045.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 130. Train loss: 0.3259272575378418. Test loss: 0.3219146430492401.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 140. Train loss: 0.3127497136592865. Test loss: 0.3088265657424927.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 150. Train loss: 0.3005062937736511. Test loss: 0.29647329449653625.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 160. Train loss: 0.2882854640483856. Test loss: 0.2841627895832062.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 170. Train loss: 0.27607035636901855. Test loss: 0.27188190817832947.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 180. Train loss: 0.2638775259256363. Test loss: 0.25964587926864624.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 190. Train loss: 0.2517319619655609. Test loss: 0.24747879803180695.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 200. Train loss: 0.23966187238693237. Test loss: 0.23540830612182617.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 210. Train loss: 0.2276974320411682. Test loss: 0.22346292436122894.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 220. Train loss: 0.21586862951517105. Test loss: 0.21167293190956116.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 230. Train loss: 0.20420679450035095. Test loss: 0.20006835460662842.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 240. Train loss: 0.19274357706308365. Test loss: 0.18867944180965424.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 250. Train loss: 0.18151052296161652. Test loss: 0.1775350123643875.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 260. Train loss: 0.17053785920143127. Test loss: 0.1666647046804428.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 270. Train loss: 0.15985483676195145. Test loss: 0.15609599649906158.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 280. Train loss: 0.1494891569018364. Test loss: 0.14585435390472412.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 290. Train loss: 0.13946563005447388. Test loss: 0.1359640508890152.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 300. Train loss: 0.12980739027261734. Test loss: 0.12644624710083008.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 310. Train loss: 0.12053437530994415. Test loss: 0.11731915920972824.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 320. Train loss: 0.11166350543498993. Test loss: 0.1085977852344513.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 330. Train loss: 0.10320815071463585. Test loss: 0.10029403865337372.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 340. Train loss: 0.0951782651245594. Test loss: 0.09241659939289093.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 350. Train loss: 0.08758025243878365. Test loss: 0.08497069031000137.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 360. Train loss: 0.0804169587790966. Test loss: 0.0779581218957901.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 370. Train loss: 0.07368754595518112. Test loss: 0.07137774676084518.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 380. Train loss: 0.06738847494125366. Test loss: 0.06522440910339355.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 390. Train loss: 0.061512697488069534. Test loss: 0.05949031189084053.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 400. Train loss: 0.05605054274201393. Test loss: 0.05416553094983101.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 410. Train loss: 0.05098992399871349. Test loss: 0.04923732206225395.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 420. Train loss: 0.04631645418703556. Test loss: 0.04469085857272148.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 430. Train loss: 0.04201403819024563. Test loss: 0.04050986096262932.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 440. Train loss: 0.03806533105671406. Test loss: 0.03667663782835007.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 450. Train loss: 0.034451890736818314. Test loss: 0.033172354102134705.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 460. Train loss: 0.03115438763052225. Test loss: 0.02997760847210884.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 470. Train loss: 0.02815305069088936. Test loss: 0.027072694152593613.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 480. Train loss: 0.025427956134080887. Test loss: 0.024437768384814262.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 490. Train loss: 0.022959405556321144. Test loss: 0.02205342799425125.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 500. Train loss: 0.020727905444800854. Test loss: 0.019900336861610413.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 510. Train loss: 0.018714629113674164. Test loss: 0.017959974706172943.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 520. Train loss: 0.016901462338864803. Test loss: 0.01621423102915287.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 530. Train loss: 0.015271017793565989. Test loss: 0.014646082185208797.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 540. Train loss: 0.013806858565658331. Test loss: 0.013239379972219467.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 550. Train loss: 0.012493470218032598. Test loss: 0.011978895403444767.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 560. Train loss: 0.011316515505313873. Test loss: 0.010850309394299984.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 570. Train loss: 0.010262649040669203. Test loss: 0.009840489365160465.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 580. Train loss: 0.009319362696260214. Test loss: 0.008937345817685127.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 590. Train loss: 0.008475392125546932. Test loss: 0.008129711262881756.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 600. Train loss: 0.007720276713371277. Test loss: 0.007407612167298794.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 610. Train loss: 0.007044532801955938. Test loss: 0.006761807017028332.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 620. Train loss: 0.006439672550186515. Test loss: 0.006184041500091553.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 630. Train loss: 0.005897914757952094. Test loss: 0.005666851066052914.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 640. Train loss: 0.005412437254562974. Test loss: 0.0052034384571015835.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 650. Train loss: 0.004976924858056009. Test loss: 0.004787955898791552.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 660. Train loss: 0.004585906630381942. Test loss: 0.0044149598106741905.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 670. Train loss: 0.004234463325701654. Test loss: 0.004079681821167469.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 680. Train loss: 0.003918194328434765. Test loss: 0.0037779472768306732.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 690. Train loss: 0.0036331575829535723. Test loss: 0.003506028326228261.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 700. Train loss: 0.0033759172074496746. Test loss: 0.0032605892047286034.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 710. Train loss: 0.003143410081975162. Test loss: 0.0030386741273105145.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 720. Train loss: 0.0029329126700758934. Test loss: 0.002837659092620015.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 730. Train loss: 0.0027420241967774928. Test loss: 0.00265524722635746.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 740. Train loss: 0.002568628580775112. Test loss: 0.0024893959052860737.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 750. Train loss: 0.0024108492652885616. Test loss: 0.002338321413844824.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 760. Train loss: 0.0022670335019938648. Test loss: 0.002200424438342452.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 770. Train loss: 0.0021357174264267087. Test loss: 0.002074338961392641.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 780. Train loss: 0.0020155872334726155. Test loss: 0.001958876848220825.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 790. Train loss: 0.0019055148004554212. Test loss: 0.0018529793014749885.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 800. Train loss: 0.001804534811526537. Test loss: 0.0017557364189997315.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 810. Train loss: 0.0017117765382863581. Test loss: 0.0016663246788084507.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 820. Train loss: 0.001626527402549982. Test loss: 0.0015840240521356463.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 830. Train loss: 0.0015481006703339517. Test loss: 0.0015082627069205046.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 840. Train loss: 0.0014759356854483485. Test loss: 0.0014384790556505322.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 850. Train loss: 0.0014095103542786092. Test loss: 0.0013741833390668035.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 860. Train loss: 0.0013483546499628574. Test loss: 0.0013149421429261565.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 870. Train loss: 0.0012920440931338817. Test loss: 0.0012603556970134377.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 880. Train loss: 0.0012401780404616147. Test loss: 0.0012100657913833857.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 890. Train loss: 0.0011924076243303716. Test loss: 0.0011637257412075996.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 900. Train loss: 0.0011483918060548604. Test loss: 0.0011210308875888586.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 910. Train loss: 0.0011078261013608426. Test loss: 0.0010816920548677444.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 920. Train loss: 0.0010704267479013652. Test loss: 0.0010454390430822968.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 930. Train loss: 0.0010359418229199946. Test loss: 0.0010120092192664742.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 940. Train loss: 0.001004139136057347. Test loss: 0.0009811694035306573.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 950. Train loss: 0.0009747917065396905. Test loss: 0.0009527064394205809.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 960. Train loss: 0.0009476944687776268. Test loss: 0.000926427892409265.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 970. Train loss: 0.0009226581023540348. Test loss: 0.0009021559380926192.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 980. Train loss: 0.0008995089738164097. Test loss: 0.0008797339396551251.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Epoch 990. Train loss: 0.000878091057529673. Test loss: 0.0008590014185756445.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, x2 = torch.utils.data.random_split(torch.linspace(-math.pi, math.pi, 20000, dtype=dtype), [16000, 4000], generator=torch.Generator(device=torch.device('cuda')).manual_seed(42))\n",
    "x, x2 = torch.Tensor([b for idx, b in enumerate(x.dataset) if idx in x.indices]).to(device), torch.Tensor([c for idx, c in enumerate(x2.dataset) if idx in x2.indices]).to(device)\n",
    "# torch.linspace(-math.pi, math.pi, 10000, dtype=dtype)\n",
    "y = torch.cos(x)\n",
    "y2 = torch.cos(x2)\n",
    "\n",
    "lossy1, lossy2, lossy3 = list(), list(), list()\n",
    "epochx1, epochx2, epochx3 = list(), list(), list()\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "epochs = 1000\n",
    "lr = 1e-3\n",
    "batch_size=8000\n",
    "optimizer1 = torch.optim.SGD(cos_model1.parameters(), lr=lr)\n",
    "train_dataloader = DataLoader(TensorDataset(x.unsqueeze(1),y.unsqueeze(1)), batch_size=batch_size)\n",
    "val_dataloader = DataLoader(TensorDataset(x2.unsqueeze(1),y2.unsqueeze(1)), batch_size=batch_size)\n",
    "\n",
    "display(\"Training on original loss function\")\n",
    "for epoch in range(epochs):\n",
    "    test_loss = train_loop(train_dataloader, cos_model1, loss_fn, optimizer1, epoch)\n",
    "        \n",
    "    if epoch % 10 == 0:\n",
    "        display(f\"Epoch {epoch}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1fe9ee5c-a8aa-47d2-91d0-9bbc0ba71c90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gradient_norm(model, dataloader, loss_fn, optimize):\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        y_pred = model(X)\n",
    "        y_pred = y_pred.unsqueeze(1)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss.backward()\n",
    "        \n",
    "    grad_all = 0\n",
    "    for params in model.parameters():\n",
    "        grad = 0.0\n",
    "        if params.grad is not None:\n",
    "            grad = params.grad.detach().cpu().data.norm(2)\n",
    "            grad_all += grad.item() ** 2\n",
    "    grad_norm = grad_all ** 0.5\n",
    "    return grad_norm\n",
    "\n",
    "def minimum_ratio(model, dataloader, loss_fn, optimize):\n",
    "    model.train()\n",
    "    vals = 0\n",
    "    length = 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        y_pred = model(X)\n",
    "        y_pred = y_pred.unsqueeze(1)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimize.step()\n",
    "        weights=torch.Tensor().to(device)\n",
    "        for name, params in model.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                #print(name, len(params), params.shape)\n",
    "                hess = torch.func.hessian(lambda x: x)(torch.nn.utils.parameters_to_vector(params).to(device)) \n",
    "                eigs_vals = torch.linalg.eigvalsh(hess)\n",
    "                display(eigs_vals)\n",
    "                vals += torch.sum(eigs_vals > 0).item()\n",
    "                length+=len(eigs_vals)\n",
    "    return vals/length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5c83ba45-0b0f-4cef-ba14-4080229b1670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'0: gradient norm: 0.04588260363377215. min_ratio: 0.0. val_loss: 0.0007256894605234265'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m train_loop(train_dataloader, cos_model1, loss_fn, optimizer1, epoch)\n\u001b[1;32m      3\u001b[0m norm \u001b[38;5;241m=\u001b[39m gradient_norm(cos_model1, train_dataloader, loss_fn, optimizer1)\n\u001b[0;32m----> 4\u001b[0m min_ratio \u001b[38;5;241m=\u001b[39m \u001b[43mminimum_ratio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcos_model1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m val_loss \u001b[38;5;241m=\u001b[39m val_loop(val_dataloader, cos_model1, loss_fn, epoch)\n\u001b[1;32m      6\u001b[0m display(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: gradient norm: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnorm\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. min_ratio: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmin_ratio\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. val_loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[75], line 33\u001b[0m, in \u001b[0;36mminimum_ratio\u001b[0;34m(model, dataloader, loss_fn, optimize)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m name:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m#print(name, len(params), params.shape)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     hess \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfunc\u001b[38;5;241m.\u001b[39mhessian(\u001b[38;5;28;01mlambda\u001b[39;00m x: x)(torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mparameters_to_vector(params)\u001b[38;5;241m.\u001b[39mto(device)) \n\u001b[0;32m---> 33\u001b[0m     eigs_vals \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meigvalsh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhess\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     display(eigs_vals)\n\u001b[1;32m     35\u001b[0m     vals \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(eigs_vals \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.hw/lib/python3.11/site-packages/torch/utils/_device.py:79\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m---> 79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    train_loop(train_dataloader, cos_model1, loss_fn, optimizer1, epoch)\n",
    "    norm = gradient_norm(cos_model1, train_dataloader, loss_fn, optimizer1)\n",
    "    min_ratio = minimum_ratio(cos_model1, train_dataloader, loss_fn, optimizer1)\n",
    "    val_loss = val_loss = val_loop(val_dataloader, cos_model1, loss_fn, epoch)\n",
    "    display(f'{epoch}: gradient norm: {norm}. min_ratio: {min_ratio}. val_loss: {val_loss}')\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5dde80d7-bd3b-4983-a39d-6df4da583140",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor([1,2]).view(2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9da238-2729-42a7-b162-e1dac59f2a3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
